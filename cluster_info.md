# Компоненты кластера:

* Etcd
key-value хранилище, в котором хранится вся информация о кластере.
* API-server
* Controller-manager
* Scheduler
* Kubelet
* Kube-proxy

+ Контейнеризация
Система контейнеризации, поддерживающая Container Runtime Interface.
* Сеть
Container Network Interface.
* DNS
Service Discovery (coredns - default).

# ETCD

Работает по протоколу RAFT.
Etcdctl - утилита управления кластером ETCD (в основном используется для проверки здоровья кластера и вохможности делать снапшоты).
Требует быстрых дисков и стабильного широкого линка.

# API-server

* Центральный компонент кластера kubernetes.
* Единственный, кто общается с Etcd.
* Работает по REST API
* Authentication and authorization
Так как он единственный, кто общается с Etcd, работает по TLS и занимается авторизацией и аутентификацией пользователей

**Встроенные подсказки**
Помимо прочего в API server встроена документация по всем объектам, которые мы можем создать в кластере.
Для получения этой документации используется команда **kubectl explain** <type>.<fieldName>[.<fieldName>]
Таким образом, например, мы можем посмотреть описание всех доступных полей в pod'е:
**kubectl explain pod**
Или в spec pod'а:
**kubectl explain pod.spec**
Можно также получить список всех API объектов доступных в кластере:
**kubectl api-resources**
И посмотреть описание при помощи explain любого неизвестного ресурса.
Так что, если у Вас есть kubectl и доступ к кластеру Kubernetes. Вы всегда можете не выходя за пределы консоли получить документацию по любому полю и объекту. Это очень сильно экономит время при работе с кластером.

# Controller-manager

Комплекс различных контроллеров, например:
* Node controller
* Replicaset controller
* Endpoints controller
(Когда создаётся объект (например, сервис) в фоне создаются эндпоинты
* etc
* GarbageCollector (например, удаляет 11-ые replicasets)

Почти для всех абстракций кубернетеса есть свой контроллер.
Общая роль контроллеров - следить за состоянием и созданием новых объектов в рамках своей зоны ответственности.
Controller-manager генерирует описания replicaset'ов и pod'ов из объекта deployment

# Scheduler

Назначает pods на ноды, учитывая:
* QoS
* Affinity / anti-affinity
* Requested resources
* Priority Class

**Priority Class**
Подам можно выставлять приоритет. Эвакуируются и запускаются в первую очередь поды с более высоким приоритетом.
Если ресурсов не хватает - в первую очередь гасятся поды с более низким приоритетом.

**QoS**
Если не задано реквестов и лимитов, поду присваивается класс Best Effort.
Если заданы реквесты и лимиты, но они не равны, присваивается Burstable.
Если равны - Quaranteed.

Для kubernetes наиболее важны поды с Quaranteed, затем приоритет у Burstable.

Scheduler делает watch в Kube-API. Как только видит, что появилась новая запись, начинает работу.
**Поле NodeName как правило заполняется после того, как scheduler выбрал в соответствии с правилами подходящую ноду.**
После чего Kube-API-server записывает это в Etcd.

Самый быстрый способ в случае проблем с controlplane кластера продиагностировать неисправность - это выполнить команду
**kubectl get componentstatuses**

# Kubelet

Работает на каждой ноде кластера.
Единственный компонент, работающий не в Docker (условно можно назвать systemd приложением).

**!!!**
также смотрит в Kube-API и когда видит запрос с созданием нового пода, где NodeName - это принадлежащий ему адрес, начинает действовать:
Отдаёт команды Docker daemon'у и фактически создаёт pods
(отдает Docker'у команды для запуска контейнеров).

Соответственно Kubelet может запускать pod'ы без участия API server
Постоянно мониторит происходящее с подами и транслирует статус в API-server.
Контролирует работу наших подов, следит за их health check'ами.

**Компоненты Kubernetes в порядке их подключения к процессу запуска приложения**

1. kubectl
2. API-server
3. Controller-manager
4. Scheduler
5. Kubelet

